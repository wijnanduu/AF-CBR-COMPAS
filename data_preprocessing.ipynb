{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "In this notebook we extract the data from the SQL database provided by ProPublica. We do this (rather than just use their compas-scores.csv) for a number of reasons: \n",
    "* The compas-scores.csv only contains the decile scores, not the raw scores. We want to have access to both. \n",
    "* The compas-scores.csv does not contain the recommended supervision level scores. \n",
    "* The compas-scores.csv does not contain marital status information. \n",
    "* We want to add an 'age-at-first-arrest' feature, as the compas practisioner's guide lists this as one of the inputs to the compas program. \n",
    "* For the third data analysis we want to extract all the scores for the three types of compas risk assessments as separate files.\n",
    "\n",
    "To do this, we import the SQL tables from `compas.db` to pandas dataframes. For the first four points above, we compute the desired information and merge the tables into a single dataframe which is then written to `data/compas.csv`. This will be csv used for our first and second data analyses of the paper. Then, for the last point above, we process just the `compas` table into three further dataframes, containing the raw, decile, and text scores of all the rows corresponding to the three types of compas risk scores. These are then also written to csv files, for our third data analysis of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import sqlite3\n",
    "from z3 import * # must be at least version 4.12.2. \n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Class for a \"functional\" dictionary, which can be also be accessed with round brackets. \n",
    "class fdict(dict):\n",
    "    def __call__(self, k):\n",
    "        return self[k] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames from the SQL database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_database.db' with the path to your .db file\n",
    "database_path = 'data/compas.db'\n",
    "\n",
    "# Establish a connection to the database\n",
    "conn = sqlite3.connect(database_path)\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute a query to retrieve the names of all tables\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Fetch all table names except the 'summary' table, which is empty. \n",
    "tables = [table[0] for table in cursor.fetchall() if table[0] != \"summary\"]\n",
    "\n",
    "# Read the tables as dataframes and store in a dict. \n",
    "dfd = {table : pd.read_sql_query(f\"SELECT * FROM {table}\", conn) for table in tables}\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute age-at-first-arrest column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dfd['casearrest'] by person_id and keep only the row with the earliest 'arrest_date' date. \n",
    "first_arrest = dfd['casearrest'].sort_values('arrest_date').groupby('person_id').first().reset_index() \n",
    "first_arrest = first_arrest[['arrest_date', 'person_id']]\n",
    "\n",
    "# Copy the people df - this will be appended with information from other tables. \n",
    "ext_people = dfd['people'].copy()\n",
    "\n",
    "# Remove the trailing \"00:00:00.000000\" from dob. \n",
    "ext_people['dob'] = ext_people['dob'].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "# Rename the 'id' column in ext_people to 'person_id', for merging with other tables.\n",
    "ext_people = ext_people.rename(columns={'id': 'person_id'})\n",
    "\n",
    "# Merge ext_people with first_arrest.\n",
    "ext_people = ext_people.merge(right=first_arrest, on='person_id', how='left', suffixes=(None, '_fa'))\n",
    "\n",
    "# Replace NaN values in the 'arrest_date' column with \"2016-01-01 00:00:00.000000\".\n",
    "ext_people['arrest_date'] = ext_people['arrest_date'].fillna(\"No_arrest\")\n",
    "\n",
    "# Change the column type of arrest_date to string, and remove trailing \"00:00:00.000000\".\n",
    "ext_people['arrest_date'] = ext_people['arrest_date'].astype(str)\n",
    "ext_people['arrest_date'] = ext_people['arrest_date'].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "# Drop extraneous columns. \n",
    "ext_people = ext_people.drop(columns=['first', 'last', 'race', 'name', 'compas_screening_date', 'score_text', 'violent_recid', 'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number', 'c_days_from_compas', 'c_arrest_date', 'c_offense_date', 'c_charge_degree', 'c_charge_desc', 'is_recid', 'num_r_cases', 'r_case_number', 'r_charge_degree', 'r_days_from_arrest', 'r_offense_date', 'r_charge_desc', 'r_jail_in', 'r_jail_out', 'is_violent_recid', 'num_vr_cases', 'vr_case_number', 'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc', 'age_cat'])\n",
    "\n",
    "# Compute difference in dates (in string format) in years. \n",
    "def time_diff(s1, s2, s3):\n",
    "    if s2 == \"No_arrest\":\n",
    "        return s3\n",
    "    else:\n",
    "        format = \"%Y-%m-%d\"\n",
    "        d1 = datetime.strptime(s1, format)\n",
    "        d2 = datetime.strptime(s2, format)\n",
    "        return round((d2 - d1).days / 365.25)\n",
    "\n",
    "# Compute the time difference in years between date of birth (dob) and first arrest date (arrest_date). \n",
    "ext_people['age_at_first_arrest'] = ext_people.apply(lambda row: time_diff(row['dob'], row['arrest_date'], row['age']), axis=1)\n",
    "\n",
    "# Drop the arrest_date and dob columns.\n",
    "ext_people = ext_people.drop(columns=['arrest_date', 'dob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join marital status and risk scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_df = dfd['compas'].copy()\n",
    "\n",
    "# Filter rows with invalid scores. \n",
    "compas_df = compas_df[compas_df[\"score_text\"] != \"N/A\"]\n",
    "\n",
    "# Remove COPMAS assessments from the df other than the first. \n",
    "# First, sort the DataFrame by person_id and compas_assessment_id\n",
    "compas_df_sorted = compas_df.sort_values(by=['person_id', 'compas_assessment_id'])\n",
    "first_screening = compas_df_sorted.groupby('person_id').first().reset_index()\n",
    "first_screening_df = compas_df_sorted.merge(first_screening[['person_id', 'compas_assessment_id']], on=['person_id', 'compas_assessment_id'])\n",
    "\n",
    "# Drop extraneous columns. \n",
    "cols = ['id', 'type_of_assessment', 'raw_score', 'decile_score', 'score_text', 'person_id', 'marital_status', 'rec_supervision_level']\n",
    "dcols = [col for col in first_screening_df.columns if col not in cols]\n",
    "first_screening_df = first_screening_df.drop(columns=dcols)\n",
    "\n",
    "# Each person now has three rows in the column corresponding to the recidivism, \n",
    "# violent recidivism, and FTA risk scores. We now change these into three separate \n",
    "# columns rather than three rows, using pivot. \n",
    "pivoted_df = first_screening_df.pivot(index='person_id', columns='type_of_assessment', values=['raw_score', 'decile_score', 'score_text'])\n",
    "pivoted_df.columns = ['_'.join(col).strip().replace(' ', '_').lower() for col in pivoted_df.columns.values]\n",
    "pivoted_df.reset_index(inplace=True)\n",
    "\n",
    "# Merge the pivoted DataFrame with the original DataFrame to retain other columns\n",
    "# Drop duplicates to ensure each person_id has only one row\n",
    "other_columns = first_screening_df.drop(['raw_score', 'decile_score', 'score_text', 'type_of_assessment'], axis=1).drop_duplicates(subset='person_id')\n",
    "final_df = pd.merge(other_columns, pivoted_df, on='person_id')\n",
    "ext_people = ext_people.merge(final_df, on='person_id', how='left')\n",
    "\n",
    "# Drop some unneeded columns.\n",
    "ext_people = ext_people.drop(columns=['id', 'person_id', 'decile_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename some columns and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten the column names. \n",
    "repl = {\n",
    "    'raw_score' : 'rs',\n",
    "    'decile_score' : 'ds',\n",
    "    'rec_supervision_level' : 'slevel',\n",
    "    'risk_of_failure_to_appear' : 'fta', \n",
    "    'risk_of_recidivism' : 'grecid', \n",
    "    'risk_of_violence' : 'vrecid',\n",
    "    'score_text_fta' : 'fta_text',\n",
    "    'score_text_grecid' : 'grecid_text', \n",
    "    'score_text_vrecid' : 'vrecid_text',\n",
    "    'sex' : 'male',\n",
    "}\n",
    "for k in repl:\n",
    "    ext_people.columns = ext_people.columns.str.replace(k, repl[k])\n",
    "\n",
    "# Change the type of the 'ds_*' columnns to int.\n",
    "for c in ext_people.columns:\n",
    "    if 'ds_' in c:\n",
    "        ext_people[c] = ext_people[c].astype(float).astype(pd.Int64Dtype())\n",
    "\n",
    "# Change 'male' column values to 1 and 0. \n",
    "r_dict = {\"Male\" : 1, \"Female\" : 0}\n",
    "ext_people[\"male\"] = ext_people[\"male\"].replace(r_dict)\n",
    "\n",
    "# Change sex column datatype to int64.\n",
    "ext_people[\"male\"] = ext_people[\"male\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the lists of binnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfd[\"compas\"].copy()\n",
    "df = df[df[\"score_text\"] != \"N/A\"]\n",
    "\n",
    "fta_bins = df[df[\"type_of_assessment\"] == \"Risk of Failure to Appear\"]\n",
    "fta_bins = fta_bins[[\"raw_score\", \"decile_score\", \"score_text\"]].dropna()\n",
    "\n",
    "grecid_bins = df[df[\"type_of_assessment\"] == \"Risk of Recidivism\"]\n",
    "grecid_bins = grecid_bins[[\"raw_score\", \"decile_score\", \"score_text\"]].dropna()\n",
    "\n",
    "vrecid_bins = df[df[\"type_of_assessment\"] == \"Risk of Violence\"]\n",
    "vrecid_bins = vrecid_bins[[\"raw_score\", \"decile_score\", \"score_text\"]].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out to `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing frames to csv files.\n"
     ]
    }
   ],
   "source": [
    "# Write the ext_people df to a csv file in the 'data' subfolder. \n",
    "ext_people = ext_people.dropna()\n",
    "ext_people.to_csv('data/compas.csv', index=False)\n",
    "\n",
    "# Write out the bin frames.\n",
    "fta_bins.to_csv('data/fta_bins.csv', index=False)\n",
    "grecid_bins.to_csv('data/grecid_bins.csv', index=False)\n",
    "vrecid_bins.to_csv('data/vrecid_bins.csv', index=False)\n",
    "\n",
    "print(\"Finished writing frames to csv files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
